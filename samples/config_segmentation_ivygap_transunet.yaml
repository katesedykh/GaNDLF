# affix version
version:
  {
    minimum: 0.0.14,
    maximum: 0.0.14 # this should NOT be made a variable, but should be tested after every tag is created
  }
# Choose the model parameters here
model:
  {
    dimension: 2, # the dimension of the model and dataset: defines dimensionality of computations
    base_filters: 16, # Set base filters: number of filters present in the initial module of the U-Net convolution; for IncU-Net, keep this divisible by 4
    architecture: resunet, # options: unet, resunet, fcn, uinc
    final_layer: sigmoid, # can be either sigmoid, softmax or none (none == regression)
    class_list: [0,3], # Set the list of labels the model should train on and predict
    ignore_label_validation: 0,
    amp: False, # Set if you want to use Automatic Mixed Precision for your operations or not - options: True, False
    n_channels: 3, # set the input channels - useful when reading RGB or images that have vectored pixel types
  }
# metrics to evaluate the validation performance
metrics:
  - dice
  - precision: {multiclass: False}
  - iou
  - recall: {multiclass: False}
# this is to enable or disable lazy loading - setting to true reads all data once during data loading, resulting in improvements
# in I/O at the expense of memory consumption
in_memory: False
# Set the Modality : rad for radiology, path for histopathology
modality: path
# Patch size during training - 2D patch for breast images since third dimension is not patched 
patch_size: [512, 512]
# Set the stride size : Not needed during training and validation, only during inference.
stride_size: [256, 256]
# uniform: UniformSampler or label: LabelSampler
patch_sampler: label
# Number of epochs
num_epochs: 100
# Set the patience - measured in number of epochs after which, if the performance metric does not improve, exit the training loop - defaults to the number of epochs
patience: 10
# Set the batch size
batch_size: 4
# Set the initial learning rate
learning_rate: 0.01
# Learning rate scheduler - options: triangle, exp, reduce-on-lr, step, more to come soon - default hyperparameters can be changed thru code
scheduler: triangle
# Set which loss function you want to use - options : 'dc' - for dice only, 'dcce' - for sum of dice and CE and you can guess the next (only lower-case please)
# options: dc (dice only), ce (), dcce (sume of dice and ce), mse () ...
# mse is the MSE defined by torch and can define a variable 'reduction'; see https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss
# use mse_torch for regression/classification problems and dice for segmentation
loss_function: dc
# Which optimizer do you want to use - adam/sgd
optimizer: adam
# this parameter controls the nested training process
# performs randomized k-fold cross-validation
# split is performed using sklearn's KFold method
# for single fold run, use '-' before the fold number
nested_training:
  {
    testing: -8, # this controls the testing data splits for final model evaluation; use '1' if this is to be disabled
    validation: -8 # this controls the validation data splits for model training
  }

# Histopathology Slide level to train or infer from, this is important since magnification is different
# on different levels and therefore is one of the most important factors for training these neural networks
# as they are not agnostic to the different texture and need to understand data at a good enough level.
slide_level: 1
# parallel training on HPC - here goes the command to prepend to send to a high performance computing
# cluster for parallel computing during multi-fold training
# not used for single fold training
# this gets passed before the training_loop, so ensure enough memory is provided along with other parameters
# that your HPC would expect
# ${outputDir} will be changed to the outputDir you pass in CLI + '/${fold_number}'
# ensure that the correct location of the virtual environment is getting invoked, otherwise it would pick up the system python, which might not have all dependencies
parallel_compute_command: 'qsub -b y -l gpu -l h_vmem=32G -cwd -o ${outputDir}/\$JOB_ID.stdout -e ${outputDir}/\$JOB_ID.stderr `pwd`/sge_wrapper _correct_location_of_virtual_environment_/venv/bin/python'
## queue configuration - https://torchio.readthedocs.io/data/patch_training.html?#queue
# this determines the maximum number of patches that can be stored in the queue. Using a large number means that the queue needs to be filled less often, but more CPU memory is needed to store the patches
q_max_length: 20
# this determines the number of patches to extract from each volume. A small number of patches ensures a large variability in the queue, but training will be slower
q_samples_per_volume: 1
# this determines the number subprocesses to use for data loading; '0' means main process is used
q_num_workers: 2
# used for debugging
q_verbose: False

save_output: True
